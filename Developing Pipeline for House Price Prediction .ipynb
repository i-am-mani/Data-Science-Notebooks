{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn.pipeline import TransformerMixin,Pipeline,FeatureUnion,make_pipeline,make_union\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import LabelEncoder,FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sns.set()\n",
    "\n",
    "\n",
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n",
    "        display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset size = 1460\n",
      "Test Dataset size = 1459\n"
     ]
    }
   ],
   "source": [
    "raw_train_data = pd.read_csv('data/train.csv')\n",
    "print(f'Train Dataset size = {raw_train_data.shape[0]}')\n",
    "raw_test_data = pd.read_csv('data/test.csv')\n",
    "print(f'Test Dataset size = {raw_test_data.shape[0]}')\n",
    "IDS = raw_test_data.Id\n",
    "\n",
    "# Convert SalePrice to log value\n",
    "raw_train_data.SalePrice = np.log(raw_train_data.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Creating Pipeline\n",
    "\n",
    "+ Pipelines solves some major issues relating pre-processing data for consumption of model. Often we end up with notebooks which have messy structure for preprocessing, in worst case we might end up leaking our data, as its a common pratice to merge train and test data to simplify preprocessing - This strategy isn't scalable, and falls apart fairly quick.\n",
    "\n",
    "+ Our pipeline will manage continuous as well as categorical data, We indend to, \n",
    "    - encoding categorical data \n",
    "    - optionally provide One Hot Encoding (not implemented yet)\n",
    "    - Treat missing values\n",
    "        - For categorical, use most repeated values or simply replace them with a comman label\n",
    "        - For Continuous, either use median value\n",
    "    - And more, but this notebook will restrict to most common preprocessing steps.\n",
    "\n",
    "#### Overview\n",
    "\n",
    "+ Our **Final Pipeline**, will consist of a **Feature Union** which would compose **Continuous and Categorical Pipelines**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Creating Custom Transformers\n",
    "\n",
    "---\n",
    "\n",
    "#### We create following transformers:\n",
    "\n",
    "+ **CategoricalDataFilter**\n",
    "    - retrieving Categorical features\n",
    "\n",
    "+ **ContinuousDataFilter**\n",
    "    - retrieving Continuous feature\n",
    "\n",
    "+ **CategoricalMapper**\n",
    "    - encoding categorical feature values to integer space\n",
    "\n",
    "+ **MedianImputer**\n",
    "    - filling missing features with median values of each feature.\n",
    "    \n",
    "---\n",
    "\n",
    "#### Why we need custom transformer?\n",
    "\n",
    "Custom Transformer allow us to store feature specific values during fit, these can be used in transform and eventually this will ensure that data leak does not occur. \n",
    "\n",
    "Eg. We use median values extracted from data which is used for fitting, and use the same in transforming\n",
    "\n",
    "\n",
    "#### Note: We have used **FunctionTransformer**, basically its a convinence function in which we don't have to provide logic for fit, we can tranform the data and return the transformed data, it would act just like a custom transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour',\n",
       "       'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1',\n",
       "       'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
       "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC',\n",
       "       'CentralAir', 'Electrical', 'LowQualFinSF', 'BsmtFullBath',\n",
       "       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',\n",
       "       'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces',\n",
       "       'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageCars', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', '3SsnPorch', 'PoolArea', 'PoolQC', 'Fence',\n",
       "       'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CategoricalDataFilter(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"Transformer for extracting categorical features, based on number of unique values present in a feature\"\"\"\n",
    "    \n",
    "    def __init__(self,max_unique=26):\n",
    "        \"\"\"\n",
    "            Parameters:\n",
    "            ----------\n",
    "            max_unique: maximum unique values permissable for feature to be considered as Categorical feature \n",
    "        \"\"\"        \n",
    "        self.max_unique = max_unique        \n",
    "        # capture categorical feature names, return these features in transform.\n",
    "        self.categorical_features = []\n",
    "        \n",
    "    def fit(self,X,y=None):                \n",
    "        assert type(X) == pd.DataFrame\n",
    "\n",
    "        for feature in X.columns:\n",
    "            n_unique = X[feature].nunique()\n",
    "            # Categorical Feature only if n_unqiue is less then max_unique\n",
    "            if n_unique <= self.max_unique: \n",
    "                self.categorical_features.append(feature)        \n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):        \n",
    "        return X[self.categorical_features]\n",
    "        \n",
    "\n",
    "class ContinuousDataFilter(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"\n",
    "        Transformer for extracting continuous features, based on number of unique values present in a feature\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self,min_unique=26):  \n",
    "        \"\"\"\n",
    "            parameters:\n",
    "            -----------\n",
    "            min_unique: minimum number of unique values a feature should have to be considered continuous type\n",
    "        \"\"\"\n",
    "        self.min_unique = min_unique        \n",
    "        self.continuous_features = []\n",
    "        \n",
    "    def fit(self,X,y=None):                \n",
    "        assert type(X) == pd.DataFrame\n",
    "\n",
    "        for feature in X.columns:\n",
    "            n_unique = X[feature].nunique()\n",
    "            if n_unique > self.min_unique:\n",
    "                self.continuous_features.append(feature)        \n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):        \n",
    "        return X[self.continuous_features].astype('category')        \n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "cat_df = CategoricalDataFilter().fit(raw_train_data).transform(raw_train_data)\n",
    "\n",
    "cont_df = ContinuousDataFilter().fit(raw_train_data).transform(raw_train_data)\n",
    "\n",
    "display(len(cat_df.columns))\n",
    "\n",
    "display(len(cont_df.columns))\n",
    "\n",
    "display(cat_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>...</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  MSZoning  Street  Alley  LotShape  LandContour  Utilities  \\\n",
       "0              7         5       5      5         5            5          5   \n",
       "1              5         5       5      5         5            5          5   \n",
       "2              7         5       5      5         7            5          5   \n",
       "3              7         5       5      5         7            5          5   \n",
       "4              7         5       5      5         7            5          5   \n",
       "...          ...       ...     ...    ...       ...          ...        ...   \n",
       "1455           7         5       5      5         5            5          5   \n",
       "1456           5         5       5      5         5            5          5   \n",
       "1457           7         5       5      5         5            5          5   \n",
       "1458           5         5       5      5         5            5          5   \n",
       "1459           5         5       5      5         5            5          5   \n",
       "\n",
       "      LotConfig  LandSlope  Neighborhood  ...  3SsnPorch  PoolArea  PoolQC  \\\n",
       "0             5          5             7  ...          5         5       5   \n",
       "1            10          5            22  ...          5         5       5   \n",
       "2             5          5             7  ...          5         5       5   \n",
       "3             7          5            10  ...          5         5       5   \n",
       "4            10          5            13  ...          5         5       5   \n",
       "...         ...        ...           ...  ...        ...       ...     ...   \n",
       "1455          5          5             5  ...          5         5       5   \n",
       "1456          5          5            10  ...          5         5       5   \n",
       "1457          5          5            10  ...          5         5       5   \n",
       "1458          5          5             5  ...          5         5       5   \n",
       "1459          5          5            10  ...          5         5       5   \n",
       "\n",
       "      Fence  MiscFeature  MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0         5            5        5       5       3         0              0  \n",
       "1         5            5        5       5       1         0              0  \n",
       "2         5            5        5       5       3         0              0  \n",
       "3         5            5        5       5       2         0              2  \n",
       "4         5            5        5       8       3         0              0  \n",
       "...     ...          ...      ...     ...     ...       ...            ...  \n",
       "1455      5            5        5      10       1         0              0  \n",
       "1456     10            5        5       5       4         0              0  \n",
       "1457     11            5       15       5       4         0              0  \n",
       "1458      5            5        5      10       4         0              0  \n",
       "1459      5            5        5       7       3         0              0  \n",
       "\n",
       "[1460 rows x 61 columns]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CategoricalMapper(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"\n",
    "        Transformer for handling categorical value mapping, It ensures that the categories found in \n",
    "        fitting are only used for transforming, hence avoiding data leak. \n",
    "        \n",
    "        Any new feature value found in transform would be mapped to 'unkown' i.e. -1 nominal value\n",
    "    \"\"\"\n",
    "    def __init__(self):        \n",
    "        \n",
    "        # Preserve the mapping from feature values to encoded values.\n",
    "        self.label_encoders = {}        \n",
    "        \n",
    "        \n",
    "    def fit(self,X,y=None):        \n",
    "        \"\"\" Encode the feature values\"\"\"\n",
    "        assert type(X) == pd.DataFrame\n",
    "        \n",
    "\n",
    "        for feature in X:        \n",
    "            feature_values = X[feature].value_counts().index.values\n",
    "            label_dict = dict()\n",
    "            for idx,label in enumerate(feature_values): \n",
    "                label_dict[label] = idx\n",
    "            label_dict['unkown'] = -1 \n",
    "            self.label_encoders[feature] = label_dict\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        assert type(X) == pd.DataFrame\n",
    "        X_copy = X.copy()\n",
    "        for feature_name in X.columns:\n",
    "            encoder = self.label_encoders[feature_name]\n",
    "            for v in X[feature_name].value_counts().index.values:\n",
    "                if(v not in encoder.keys()):\n",
    "                    X_copy.replace(v,-1,inplace=True)\n",
    "                else:\n",
    "                    X_copy.replace(v,encoder[v],inplace=True)\n",
    "        return X_copy\n",
    "            \n",
    "def FillNaWithMissing(X):    \n",
    "    \"\"\"\n",
    "        Applicable only on categorical data.\n",
    "        \n",
    "        Replace 'na' values with 'missing' string, application only for categorical variables\n",
    "    \"\"\"\n",
    "    res = X.copy()\n",
    "    for fn in X.columns:    \n",
    "        res[fn] = X[fn].astype('object').fillna('Missing')\n",
    "    return res\n",
    "\n",
    "\n",
    "CategoricalMapper().fit_transform(FillNaWithMissing(cat_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class MedianImputer(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"\n",
    "        Transformer to impute missing or na fields with median value of the feature.\n",
    "        \n",
    "        Uses in SimplyImputer of sklearn internally\n",
    "        \n",
    "        Note: Only Numeric data is allowed\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Store median values of feature in fit, used while transforming\n",
    "        self.features = []\n",
    "        self.imputer = None\n",
    "        \n",
    "    def fit(self,X,y=None):\n",
    "        assert type(X) == pd.DataFrame\n",
    "        \n",
    "        self.imputers = SimpleImputer(strategy='median').fit(X)\n",
    "        self.features = X.columns\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):        \n",
    "        assert type(X) == pd.DataFrame\n",
    "        \n",
    "        for x_feature in X.columns:\n",
    "            if x_feature not in self.features:\n",
    "                raise Exception(\"Feature not found\")\n",
    "            \n",
    "        return self.imputers.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Assembling of Pipelines\n",
    "\n",
    "#### A short description about functions we about to see.\n",
    "\n",
    "##### ```make_pipeline```\n",
    "\n",
    "* It Constructs a Pipeline from the given transformers/estimators.\n",
    "* This is a shorthand for the Pipeline constructor. \n",
    "* make_pipeline internally maps names of tansformers as their lowercase form\n",
    "* Usual form of Pipeline function is:\n",
    "\n",
    "```python\n",
    "Pipeline(steps=[('standardscaler',StandardScaler()),\n",
    "                ('gaussiannb', GaussianNB())])\n",
    "\n",
    "```\n",
    "\n",
    "* In a Pipeline, a estimator is the last item in transformer list. If your using a estimator, make sure that it's the occupies the last place. \n",
    "\n",
    "* In simplified version, a pipeline simply serialize all transformers in the given order and fit that to the estimator in the end. However is a estimator is not present then it would simply return the last transformers output.\n",
    "\n",
    "* We made some multiple Pipeline object, two with only tranformers which are Continuous and Categorical transformer, and last one is the final pipeline which feeds the final neat data to our estimator.\n",
    "\n",
    "#####  ```make_union```\n",
    "\n",
    "* Similar to make_pipeline, This is a convinience function for Constructing a FeatureUnion from the given transformers.\n",
    "* This is a shorthand for the FeatureUnion constructor\n",
    "\n",
    "* A FeatureUnion composes output of independent transformers, i.e. every transformer runs in parallel.\n",
    "\n",
    "* We use FeatureUnion to compose output of Continoues and Categorical pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\home\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7904458193861086"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = raw_train_data.drop('SalePrice',axis=1)\n",
    "output_y = raw_train_data.SalePrice\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(train_data,output_y,test_size=0.2)\n",
    "\n",
    "categorical_pipeline = make_pipeline(CategoricalDataFilter(),\n",
    "                             FunctionTransformer(FillNaWithMissing,validate=False),\n",
    "                             CategoricalMapper()) \n",
    "\n",
    "continuous_pipeline = make_pipeline(ContinuousDataFilter(),\n",
    "                             MedianImputer())\n",
    "\n",
    "\n",
    "feature_union = make_union(continuous_pipeline,categorical_pipeline)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "final_pipeline = make_pipeline(feature_union,model)\n",
    "\n",
    "final_pipeline.fit(X_train,y_train)\n",
    "final_pipeline.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
